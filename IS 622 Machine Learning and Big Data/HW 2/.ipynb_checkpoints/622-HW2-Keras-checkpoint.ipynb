{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charley Ferrari\n",
    "\n",
    "DATA 622\n",
    "\n",
    "HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nnet as nnet\n",
    "import numpy as np\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='charleyferrari', api_key='oksysax3g0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll create my data array. Since I'm using Keras on top of Theano, I can keep everything within python. So, I'll just use numpy and itertools to generate my matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in product(np.linspace(-10, 10, num=100), np.linspace(-10, 10, num=100)):\n",
    "    data.append([i[0], i[1], 2*(i[0]**2) - 3*(i[1]**2) + 1])\n",
    "    \n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I'll begin building my models. The steps I'm using are as follows:\n",
    "\n",
    "Sequential() initializes the model. \n",
    "\n",
    "model.add(Dense()) adds layers. In the first layer I define the number of input dimensions, and for each layer I define an activation function.\n",
    "\n",
    "model.compile() is where I define my loss function. I can use either mean_squared_error or mean_absolute_error.\n",
    "\n",
    "\n",
    "I tried out a few iterations of this model, but for the purposes of this homework, I'll just compare mean_squared_error and mean_absolute_error. In particular, I found the choice of activation function in single layer models to be most interesting. Sigmoid functions seemed to lead to more squared off predictions (similar to picking values for a range of a function), while the tanh function led to radial patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdb905acb10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMSE = Sequential()\n",
    "\n",
    "modelMSE.add(Dense(40, input_dim=2, activation='sigmoid'))\n",
    "modelMSE.add(Dense(1))\n",
    "\n",
    "modelMSE.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "modelMSE.fit(data[:,[0,1]], data[:,[2]], nb_epoch=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdb8a8030d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMAE = Sequential()\n",
    "\n",
    "modelMAE.add(Dense(40, input_dim=2, activation='sigmoid'))\n",
    "modelMAE.add(Dense(1))\n",
    "\n",
    "modelMAE.compile(loss='mean_absolute_error', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "modelMAE.fit(data[:,[0,1]], data[:,[2]], nb_epoch=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets take a look at our source function so we have something to compare our models to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~charleyferrari/866.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side = np.sqrt(data.shape[0])\n",
    "saddlemat = np.reshape(data[:,[2]], (side, side))\n",
    "\n",
    "plotlydata = [\n",
    "    go.Surface(\n",
    "        z=saddlemat,\n",
    "        x = np.linspace(-10, 10, num=100),\n",
    "        y = np.linspace(-10, 10, num=100)\n",
    "    )\n",
    "]\n",
    "\n",
    "py.iplot(plotlydata, filename='622-hw2-saddle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets plot our predictions. Below I'll plot out my two predictions, using MAE and MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~charleyferrari/878.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from plotly import tools\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "side = np.sqrt(len(modelMSE.predict(data[:,[0,1]])))\n",
    "predmatMSE = np.reshape(modelMSE.predict(data[:,[0,1]]), (side, side))\n",
    "predmatMAE = np.reshape(modelMAE.predict(data[:,[0,1]]), (side, side))\n",
    "\n",
    "MSEdata = [\n",
    "    go.Surface(\n",
    "        z=predmatMSE,\n",
    "        x = np.linspace(-10, 10, num=100),\n",
    "        y = np.linspace(-10, 10, num=100)\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Mean Squared Error'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = MSEdata, layout = layout)\n",
    "\n",
    "py.iplot(fig, filename='622-hw2-MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the error curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~charleyferrari/880.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSEdata = [\n",
    "    go.Surface(\n",
    "        z=predmatMAE,\n",
    "        x = np.linspace(-10, 10, num=100),\n",
    "        y = np.linspace(-10, 10, num=100)\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Mean Absolute Error'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = MSEdata, layout = layout)\n",
    "\n",
    "py.iplot(fig, filename='622-hw2-MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also take a look at our error curves. Below is what we have for MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~charleyferrari/882.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ermatMSE = (saddlemat - predmatMSE)**2\n",
    "\n",
    "erMSE = [\n",
    "    go.Surface(\n",
    "        z=ermatMSE,\n",
    "        x = np.linspace(-10, 10, num=100),\n",
    "        y = np.linspace(-10, 10, num=100)\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'MSE Error Surface'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = erMSE, layout = layout)\n",
    "\n",
    "py.iplot(fig, filename='622-hw2-error-MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~charleyferrari/884.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ermatMAE = (saddlemat - predmatMAE)**2\n",
    "\n",
    "erMAE = [\n",
    "    go.Surface(\n",
    "        z=ermatMAE,\n",
    "        x = np.linspace(-10, 10, num=100),\n",
    "        y = np.linspace(-10, 10, num=100)\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'MAE Error Surface'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = erMAE, layout = layout)\n",
    "\n",
    "py.iplot(fig, filename='622-hw2-error-MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the performance seems very similar when comparing the error curves. The MAE led to a smoother prediction surface, while the MSE led to a more jagged and stepwise prediction. Both of these results are fairly stable with multiple runs of the model, but the MSE appears to be more stable than MAE (though they seem to follow the same jagged/smooth patterns).\n",
    "\n",
    "Both models also share a general shape of error curves, although as expected the MSE error curve is more jagged than the MAE error curve. Both seem to produce higher errors along the x and y axis and away from the origin (so, the middles of the edges.) This might be due to the function producing extreme values in these regions, which are over and under estimated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
